{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOb47tmzjjTozRSBTa1CpJ7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/G4zele/Deep-Learning/blob/main/Lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 395,
      "metadata": {
        "id": "zGH7OSrHHW2O"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import model_selection\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/video_games_sales.csv\")"
      ],
      "metadata": {
        "id": "3hO-QEeqOPaW"
      },
      "execution_count": 396,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_1 = sns.displot(\n",
        "    data=data,\n",
        "    x=\"platform\", y=\"global_sales\",\n",
        ")\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(15, 6)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "j8vcAbFMJT3S",
        "outputId": "aa09d68e-9b0e-48c6-b7a4-6c0abebb43f8"
      },
      "execution_count": 418,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_1 = sns.displot(\n",
        "    data=data,\n",
        "    x=\"genre\", y=\"global_sales\",\n",
        ")\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(15, 6)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "qDq1NQqIJha6",
        "outputId": "7dbcee74-ba0c-484d-8c5c-4f544bdb377d"
      },
      "execution_count": 419,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop(['name','rank','na_sales','year',\t'eu_sales',\t'jp_sales',\t'other_sales', 'global_sales'],axis=1)\n",
        "Y = data['global_sales']"
      ],
      "metadata": {
        "id": "_wDlYCkNkJdg"
      },
      "execution_count": 397,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le_platform = LabelEncoder()\n",
        "le_genre = LabelEncoder()\n",
        "le_publisher = LabelEncoder()\n",
        "\n",
        "X_platform_encoded = le_platform.fit_transform(X['platform'])\n",
        "X_genre_encoded = le_genre.fit_transform(X['genre'])\n",
        "X_publisher_encoded = le_publisher.fit_transform(X['publisher'])\n",
        "\n",
        "platform_dict = dict(zip(le_platform.transform(le_platform.classes_), le_platform.classes_))\n",
        "genre_dict = dict(zip(le_genre.transform(le_genre.classes_), le_genre.classes_))\n",
        "publisher_dict = dict(zip(le_publisher.transform(le_publisher.classes_), le_publisher.classes_))\n",
        "\n",
        "\n",
        "X['platform'] = X_platform_encoded\n",
        "X['genre'] = X_genre_encoded\n",
        "X['publisher'] = X_publisher_encoded"
      ],
      "metadata": {
        "id": "Oqw3VhCAlNrX"
      },
      "execution_count": 398,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rrfe2gtGs20K",
        "outputId": "05d1a11e-5ca1-4f4b-fbfd-38c8c169f35a"
      },
      "execution_count": 399,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       platform  genre  publisher\n",
              "14328        13      3        390\n",
              "2037         29     10        138\n",
              "486          16      2        488\n",
              "15405        19      1        109\n",
              "8762          2      0        525"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7d480ac9-05a4-4da7-9814-7cf24b916a00\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>platform</th>\n",
              "      <th>genre</th>\n",
              "      <th>publisher</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14328</th>\n",
              "      <td>13</td>\n",
              "      <td>3</td>\n",
              "      <td>390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2037</th>\n",
              "      <td>29</td>\n",
              "      <td>10</td>\n",
              "      <td>138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>486</th>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15405</th>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8762</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>525</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d480ac9-05a4-4da7-9814-7cf24b916a00')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7d480ac9-05a4-4da7-9814-7cf24b916a00 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7d480ac9-05a4-4da7-9814-7cf24b916a00');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 399
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "pFPdS1Ou_sft"
      },
      "execution_count": 429,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xlJ8Txu_JCtl",
        "outputId": "bccbc214-f24a-462e-dc21-43555f01ed7f"
      },
      "execution_count": 430,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       platform  genre  publisher\n",
              "14303        19      3        340\n",
              "13455         4      9        525\n",
              "6724         17      0        446\n",
              "898          13      9        138\n",
              "8484          4      7        465"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-049314d3-a9e0-4bf6-831a-2d75a5356285\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>platform</th>\n",
              "      <th>genre</th>\n",
              "      <th>publisher</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14303</th>\n",
              "      <td>19</td>\n",
              "      <td>3</td>\n",
              "      <td>340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13455</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6724</th>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>898</th>\n",
              "      <td>13</td>\n",
              "      <td>9</td>\n",
              "      <td>138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8484</th>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>465</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-049314d3-a9e0-4bf6-831a-2d75a5356285')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-049314d3-a9e0-4bf6-831a-2d75a5356285 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-049314d3-a9e0-4bf6-831a-2d75a5356285');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 430
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tsdKlyVJJAB",
        "outputId": "e14afd5f-0e84-4ac7-a2c7-32da05ba82f9"
      },
      "execution_count": 431,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 13278 entries, 14303 to 15795\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype\n",
            "---  ------     --------------  -----\n",
            " 0   platform   13278 non-null  int64\n",
            " 1   genre      13278 non-null  int64\n",
            " 2   publisher  13278 non-null  int64\n",
            "dtypes: int64(3)\n",
            "memory usage: 414.9 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.isna().all()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWeBJSeUJKPn",
        "outputId": "af4b190f-b8c1-426b-9b18-7be98e49a431"
      },
      "execution_count": 432,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "platform     False\n",
              "genre        False\n",
              "publisher    False\n",
              "dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 432
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YytmYU6s_qn",
        "outputId": "e60c930b-5921-48b2-fad5-eb21c938d575"
      },
      "execution_count": 433,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14303   0.03000\n",
              "13455   0.04000\n",
              "6724    0.25000\n",
              "898     1.92000\n",
              "8484    0.16000\n",
              "Name: global_sales, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 433
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "XW9o058otHKb"
      },
      "execution_count": 434,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "device_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "I2I6nEgLpz7U",
        "outputId": "66056422-b1df-4cca-f866-fcea8212d049"
      },
      "execution_count": 435,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 435
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(activation='relu', optimizer='adam', neurons=32):\n",
        "  with tf.device(device_name):\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.InputLayer(input_shape=X_train.shape[1]))\n",
        "    model.add(tf.keras.layers.Dense(neurons, activation=activation))\n",
        "    model.add(tf.keras.layers.Dense(neurons, activation=activation))\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "    model.compile(loss='mse', optimizer=optimizer)\n",
        "    return model"
      ],
      "metadata": {
        "id": "6kXrrjIlMztw"
      },
      "execution_count": 436,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'neurons': [16, 32, 64],\n",
        "    'batch_size': [32, 64],\n",
        "    'epochs': [50],\n",
        "    'optimizer': ['adam', 'rmsprop'],\n",
        "    'activation': ['relu', 'tanh']\n",
        "}\n",
        "\n",
        "model = KerasRegressor(build_fn=create_model)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=2, verbose=2)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "print(f\" : {grid.best_params_}\")\n",
        "print(f\" : {grid.best_score_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wk-Qo_lap3V7",
        "outputId": "62fb5999-9981-4c3a-81d7-5316f255da7c"
      },
      "execution_count": 456,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 24 candidates, totalling 48 fits\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-456-97de74a05359>:12: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasRegressor(build_fn=create_model)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "208/208 [==============================] - 1s 2ms/step - loss: 26.7352\n",
            "Epoch 2/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.5893\n",
            "Epoch 3/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.5509\n",
            "Epoch 4/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.5087\n",
            "Epoch 5/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.5436\n",
            "Epoch 6/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.5062\n",
            "Epoch 7/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.5398\n",
            "Epoch 8/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.5620\n",
            "Epoch 9/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6278\n",
            "Epoch 10/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.5919\n",
            "Epoch 11/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.5319\n",
            "Epoch 12/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.5925\n",
            "Epoch 13/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.5968\n",
            "Epoch 14/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.5403\n",
            "Epoch 15/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6451\n",
            "Epoch 16/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6607\n",
            "Epoch 17/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6748\n",
            "Epoch 18/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6249\n",
            "Epoch 19/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6267\n",
            "Epoch 20/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6401\n",
            "Epoch 21/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6817\n",
            "Epoch 22/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6240\n",
            "Epoch 23/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6331\n",
            "Epoch 24/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6624\n",
            "Epoch 25/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6533\n",
            "Epoch 26/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.5874\n",
            "Epoch 27/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6396\n",
            "Epoch 28/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6200\n",
            "Epoch 29/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.5498\n",
            "Epoch 30/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6273\n",
            "Epoch 31/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6493\n",
            "Epoch 32/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6531\n",
            "Epoch 33/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.6367\n",
            "Epoch 34/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.6276\n",
            "Epoch 35/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.6572\n",
            "Epoch 36/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.5614\n",
            "Epoch 37/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.6157\n",
            "Epoch 38/50\n",
            "208/208 [==============================] - 1s 5ms/step - loss: 2.6350\n",
            "Epoch 39/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.6377\n",
            "Epoch 40/50\n",
            "208/208 [==============================] - 1s 6ms/step - loss: 2.6761\n",
            "Epoch 41/50\n",
            "208/208 [==============================] - 1s 5ms/step - loss: 2.5833\n",
            "Epoch 42/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.6222\n",
            "Epoch 43/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.5481\n",
            "Epoch 44/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6733\n",
            "Epoch 45/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6568\n",
            "Epoch 46/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.5692\n",
            "Epoch 47/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.5943\n",
            "Epoch 48/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.5492\n",
            "Epoch 49/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.5784\n",
            "Epoch 50/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.5877\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5752\n",
            "[CV] END activation=relu, batch_size=32, epochs=50, neurons=16, optimizer=adam; total time=  26.6s\n",
            "Epoch 1/50\n",
            "208/208 [==============================] - 22s 2ms/step - loss: 313.1333\n",
            "Epoch 2/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7193\n",
            "Epoch 3/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5538\n",
            "Epoch 4/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5348\n",
            "Epoch 5/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5587\n",
            "Epoch 6/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5161\n",
            "Epoch 7/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.5127\n",
            "Epoch 8/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.5142\n",
            "Epoch 9/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.5229\n",
            "Epoch 10/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.5226\n",
            "Epoch 11/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.5172\n",
            "Epoch 12/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5277\n",
            "Epoch 13/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5160\n",
            "Epoch 14/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5219\n",
            "Epoch 15/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5006\n",
            "Epoch 16/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5184\n",
            "Epoch 17/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5060\n",
            "Epoch 18/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5315\n",
            "Epoch 19/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5479\n",
            "Epoch 20/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5290\n",
            "Epoch 21/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5226\n",
            "Epoch 22/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5750\n",
            "Epoch 23/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6213\n",
            "Epoch 24/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5251\n",
            "Epoch 25/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5581\n",
            "Epoch 26/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6029\n",
            "Epoch 27/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5660\n",
            "Epoch 28/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5825\n",
            "Epoch 29/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6449\n",
            "Epoch 30/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5900\n",
            "Epoch 31/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5478\n",
            "Epoch 32/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5593\n",
            "Epoch 33/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5945\n",
            "Epoch 34/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6169\n",
            "Epoch 35/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5917\n",
            "Epoch 36/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.6914\n",
            "Epoch 37/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.6072\n",
            "Epoch 38/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.6903\n",
            "Epoch 39/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.6560\n",
            "Epoch 40/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.6447\n",
            "Epoch 41/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5900\n",
            "Epoch 42/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5411\n",
            "Epoch 43/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7051\n",
            "Epoch 44/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5735\n",
            "Epoch 45/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5851\n",
            "Epoch 46/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5631\n",
            "Epoch 47/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5463\n",
            "Epoch 48/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7671\n",
            "Epoch 49/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5533\n",
            "Epoch 50/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5730\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4623\n",
            "[CV] END activation=relu, batch_size=32, epochs=50, neurons=16, optimizer=adam; total time= 1.1min\n",
            "Epoch 1/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 11.7089\n",
            "Epoch 2/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 4.0245\n",
            "Epoch 3/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.7254\n",
            "Epoch 4/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.6604\n",
            "Epoch 5/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.6313\n",
            "Epoch 6/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.5550\n",
            "Epoch 7/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.5220\n",
            "Epoch 8/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.4974\n",
            "Epoch 9/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.3829\n",
            "Epoch 10/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.5244\n",
            "Epoch 11/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.4738\n",
            "Epoch 12/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.4705\n",
            "Epoch 13/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.4476\n",
            "Epoch 14/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.3889\n",
            "Epoch 15/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.4073\n",
            "Epoch 16/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.3942\n",
            "Epoch 17/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.4635\n",
            "Epoch 18/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.2703\n",
            "Epoch 19/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.3155\n",
            "Epoch 20/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.2796\n",
            "Epoch 21/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.2406\n",
            "Epoch 22/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.2291\n",
            "Epoch 23/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.2205\n",
            "Epoch 24/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 3.1936\n",
            "Epoch 25/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 3.2084\n",
            "Epoch 26/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 3.1860\n",
            "Epoch 27/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 3.1277\n",
            "Epoch 28/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 3.0921\n",
            "Epoch 29/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.1430\n",
            "Epoch 30/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.0823\n",
            "Epoch 31/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.0505\n",
            "Epoch 32/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.0914\n",
            "Epoch 33/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.9781\n",
            "Epoch 34/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.0413\n",
            "Epoch 35/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.9770\n",
            "Epoch 36/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.0009\n",
            "Epoch 37/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.9636\n",
            "Epoch 38/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.8400\n",
            "Epoch 39/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.9051\n",
            "Epoch 40/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.8311\n",
            "Epoch 41/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.8062\n",
            "Epoch 42/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.8122\n",
            "Epoch 43/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.8007\n",
            "Epoch 44/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7920\n",
            "Epoch 45/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7603\n",
            "Epoch 46/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7640\n",
            "Epoch 47/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7469\n",
            "Epoch 48/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.8096\n",
            "Epoch 49/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7385\n",
            "Epoch 50/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7433\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4949\n",
            "[CV] END activation=relu, batch_size=32, epochs=50, neurons=16, optimizer=rmsprop; total time=  42.8s\n",
            "Epoch 1/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.1733\n",
            "Epoch 2/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.9562\n",
            "Epoch 3/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.0027\n",
            "Epoch 4/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.9578\n",
            "Epoch 5/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.9233\n",
            "Epoch 6/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.9160\n",
            "Epoch 7/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.8823\n",
            "Epoch 8/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.8692\n",
            "Epoch 9/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.8470\n",
            "Epoch 10/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.8960\n",
            "Epoch 11/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.8174\n",
            "Epoch 12/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.8599\n",
            "Epoch 13/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.8152\n",
            "Epoch 14/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.8037\n",
            "Epoch 15/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.8126\n",
            "Epoch 16/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.8277\n",
            "Epoch 17/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.8007\n",
            "Epoch 18/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.8247\n",
            "Epoch 19/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7479\n",
            "Epoch 20/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7625\n",
            "Epoch 21/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7580\n",
            "Epoch 22/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7706\n",
            "Epoch 23/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7360\n",
            "Epoch 24/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7440\n",
            "Epoch 25/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7349\n",
            "Epoch 26/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7176\n",
            "Epoch 27/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6824\n",
            "Epoch 28/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6869\n",
            "Epoch 29/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6866\n",
            "Epoch 30/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6803\n",
            "Epoch 31/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6661\n",
            "Epoch 32/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6787\n",
            "Epoch 33/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6546\n",
            "Epoch 34/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6645\n",
            "Epoch 35/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6622\n",
            "Epoch 36/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6517\n",
            "Epoch 37/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6187\n",
            "Epoch 38/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.6233\n",
            "Epoch 39/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.6529\n",
            "Epoch 40/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.6429\n",
            "Epoch 41/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.6333\n",
            "Epoch 42/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.6184\n",
            "Epoch 43/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6319\n",
            "Epoch 44/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6258\n",
            "Epoch 45/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6196\n",
            "Epoch 46/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6031\n",
            "Epoch 47/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5958\n",
            "Epoch 48/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6099\n",
            "Epoch 49/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5985\n",
            "Epoch 50/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5817\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.5256\n",
            "[CV] END activation=relu, batch_size=32, epochs=50, neurons=16, optimizer=rmsprop; total time=  42.7s\n",
            "Epoch 1/50\n",
            "208/208 [==============================] - 2s 2ms/step - loss: 81.6444\n",
            "Epoch 2/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.5724\n",
            "Epoch 3/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.5555\n",
            "Epoch 4/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.5591\n",
            "Epoch 5/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.5779\n",
            "Epoch 6/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.5119\n",
            "Epoch 7/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.5677\n",
            "Epoch 8/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6027\n",
            "Epoch 9/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6005\n",
            "Epoch 10/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.5463\n",
            "Epoch 11/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6038\n",
            "Epoch 12/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6689\n",
            "Epoch 13/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6504\n",
            "Epoch 14/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.5869\n",
            "Epoch 15/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6168\n",
            "Epoch 16/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.5968\n",
            "Epoch 17/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.8042\n",
            "Epoch 18/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7089\n",
            "Epoch 19/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.8260\n",
            "Epoch 20/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.9723\n",
            "Epoch 21/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7613\n",
            "Epoch 22/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.8328\n",
            "Epoch 23/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.8829\n",
            "Epoch 24/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.9551\n",
            "Epoch 25/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.6966\n",
            "Epoch 26/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.9448\n",
            "Epoch 27/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.8883\n",
            "Epoch 28/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.8231\n",
            "Epoch 29/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.7115\n",
            "Epoch 30/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7915\n",
            "Epoch 31/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6575\n",
            "Epoch 32/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.8901\n",
            "Epoch 33/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6768\n",
            "Epoch 34/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7999\n",
            "Epoch 35/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6867\n",
            "Epoch 36/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6868\n",
            "Epoch 37/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.8863\n",
            "Epoch 38/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7209\n",
            "Epoch 39/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6247\n",
            "Epoch 40/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7539\n",
            "Epoch 41/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.8126\n",
            "Epoch 42/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6950\n",
            "Epoch 43/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6302\n",
            "Epoch 44/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6903\n",
            "Epoch 45/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6382\n",
            "Epoch 46/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6523\n",
            "Epoch 47/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7256\n",
            "Epoch 48/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7429\n",
            "Epoch 49/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6992\n",
            "Epoch 50/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6588\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5448\n",
            "[CV] END activation=relu, batch_size=32, epochs=50, neurons=32, optimizer=adam; total time=  24.2s\n",
            "Epoch 1/50\n",
            "208/208 [==============================] - 2s 3ms/step - loss: 6.5224\n",
            "Epoch 2/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.6997\n",
            "Epoch 3/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.7556\n",
            "Epoch 4/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7499\n",
            "Epoch 5/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.9364\n",
            "Epoch 6/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7962\n",
            "Epoch 7/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7497\n",
            "Epoch 8/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7317\n",
            "Epoch 9/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7089\n",
            "Epoch 10/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7253\n",
            "Epoch 11/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.8355\n",
            "Epoch 12/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7732\n",
            "Epoch 13/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7425\n",
            "Epoch 14/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7729\n",
            "Epoch 15/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.9138\n",
            "Epoch 16/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7933\n",
            "Epoch 17/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6735\n",
            "Epoch 18/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6341\n",
            "Epoch 19/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.9747\n",
            "Epoch 20/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.8219\n",
            "Epoch 21/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6867\n",
            "Epoch 22/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.8324\n",
            "Epoch 23/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.8040\n",
            "Epoch 24/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5960\n",
            "Epoch 25/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.0664\n",
            "Epoch 26/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.6603\n",
            "Epoch 27/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.6760\n",
            "Epoch 28/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.7043\n",
            "Epoch 29/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.8502\n",
            "Epoch 30/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.7421\n",
            "Epoch 31/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9022\n",
            "Epoch 32/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7775\n",
            "Epoch 33/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.8038\n",
            "Epoch 34/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6112\n",
            "Epoch 35/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6032\n",
            "Epoch 36/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7400\n",
            "Epoch 37/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7496\n",
            "Epoch 38/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.8715\n",
            "Epoch 39/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6270\n",
            "Epoch 40/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7297\n",
            "Epoch 41/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6378\n",
            "Epoch 42/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6475\n",
            "Epoch 43/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6486\n",
            "Epoch 44/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6244\n",
            "Epoch 45/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6717\n",
            "Epoch 46/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7556\n",
            "Epoch 47/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6795\n",
            "Epoch 48/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6298\n",
            "Epoch 49/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6374\n",
            "Epoch 50/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7460\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.1376\n",
            "[CV] END activation=relu, batch_size=32, epochs=50, neurons=32, optimizer=adam; total time=  26.2s\n",
            "Epoch 1/50\n",
            "208/208 [==============================] - 2s 3ms/step - loss: 166.9032\n",
            "Epoch 2/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 12.9414\n",
            "Epoch 3/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 11.1907\n",
            "Epoch 4/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 9.8164\n",
            "Epoch 5/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 9.3162\n",
            "Epoch 6/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 8.2808\n",
            "Epoch 7/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 8.1411\n",
            "Epoch 8/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 7.8487\n",
            "Epoch 9/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 7.7858\n",
            "Epoch 10/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 7.1410\n",
            "Epoch 11/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 7.0629\n",
            "Epoch 12/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 6.9819\n",
            "Epoch 13/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 6.5010\n",
            "Epoch 14/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 6.3553\n",
            "Epoch 15/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 5.5662\n",
            "Epoch 16/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 5.2057\n",
            "Epoch 17/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 4.9626\n",
            "Epoch 18/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 4.6694\n",
            "Epoch 19/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 4.5048\n",
            "Epoch 20/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 4.3681\n",
            "Epoch 21/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.9375\n",
            "Epoch 22/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.6551\n",
            "Epoch 23/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.5581\n",
            "Epoch 24/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.5584\n",
            "Epoch 25/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.4862\n",
            "Epoch 26/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.4185\n",
            "Epoch 27/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 3.3829\n",
            "Epoch 28/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 3.3401\n",
            "Epoch 29/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 3.2582\n",
            "Epoch 30/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 3.2866\n",
            "Epoch 31/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 3.2451\n",
            "Epoch 32/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 3.1607\n",
            "Epoch 33/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.2539\n",
            "Epoch 34/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.1542\n",
            "Epoch 35/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.1218\n",
            "Epoch 36/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.1100\n",
            "Epoch 37/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.0600\n",
            "Epoch 38/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.0241\n",
            "Epoch 39/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.9967\n",
            "Epoch 40/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.9458\n",
            "Epoch 41/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.8805\n",
            "Epoch 42/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.8967\n",
            "Epoch 43/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.9398\n",
            "Epoch 44/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.8425\n",
            "Epoch 45/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.8468\n",
            "Epoch 46/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7882\n",
            "Epoch 47/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7965\n",
            "Epoch 48/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7599\n",
            "Epoch 49/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7024\n",
            "Epoch 50/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6984\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4682\n",
            "[CV] END activation=relu, batch_size=32, epochs=50, neurons=32, optimizer=rmsprop; total time=  25.1s\n",
            "Epoch 1/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 11.2563\n",
            "Epoch 2/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 7.7260\n",
            "Epoch 3/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 7.1652\n",
            "Epoch 4/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 6.2742\n",
            "Epoch 5/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 5.2253\n",
            "Epoch 6/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 4.8772\n",
            "Epoch 7/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 4.5736\n",
            "Epoch 8/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 4.1755\n",
            "Epoch 9/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 4.1233\n",
            "Epoch 10/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 4.1015\n",
            "Epoch 11/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.8788\n",
            "Epoch 12/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.5802\n",
            "Epoch 13/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.4289\n",
            "Epoch 14/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.2218\n",
            "Epoch 15/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.0630\n",
            "Epoch 16/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.8507\n",
            "Epoch 17/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6771\n",
            "Epoch 18/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4623\n",
            "Epoch 19/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.3361\n",
            "Epoch 20/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.1315\n",
            "Epoch 21/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.9154\n",
            "Epoch 22/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.8237\n",
            "Epoch 23/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7022\n",
            "Epoch 24/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5944\n",
            "Epoch 25/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5960\n",
            "Epoch 26/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6110\n",
            "Epoch 27/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5884\n",
            "Epoch 28/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5759\n",
            "Epoch 29/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5628\n",
            "Epoch 30/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5664\n",
            "Epoch 31/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.5554\n",
            "Epoch 32/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.5454\n",
            "Epoch 33/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.5552\n",
            "Epoch 34/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.5473\n",
            "Epoch 35/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.5388\n",
            "Epoch 36/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.5320\n",
            "Epoch 37/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5272\n",
            "Epoch 38/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5707\n",
            "Epoch 39/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5447\n",
            "Epoch 40/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5324\n",
            "Epoch 41/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5216\n",
            "Epoch 42/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5316\n",
            "Epoch 43/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5015\n",
            "Epoch 44/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5005\n",
            "Epoch 45/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5060\n",
            "Epoch 46/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5000\n",
            "Epoch 47/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4855\n",
            "Epoch 48/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4883\n",
            "Epoch 49/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4797\n",
            "Epoch 50/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4808\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4667\n",
            "[CV] END activation=relu, batch_size=32, epochs=50, neurons=32, optimizer=rmsprop; total time=  24.3s\n",
            "Epoch 1/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 18.5166\n",
            "Epoch 2/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7126\n",
            "Epoch 3/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.9745\n",
            "Epoch 4/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.8186\n",
            "Epoch 5/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.8957\n",
            "Epoch 6/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.1149\n",
            "Epoch 7/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.7868\n",
            "Epoch 8/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.8576\n",
            "Epoch 9/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 3.0959\n",
            "Epoch 10/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 3.2063\n",
            "Epoch 11/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.8349\n",
            "Epoch 12/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 3.1553\n",
            "Epoch 13/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.0315\n",
            "Epoch 14/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.8620\n",
            "Epoch 15/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.2831\n",
            "Epoch 16/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.2507\n",
            "Epoch 17/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.8248\n",
            "Epoch 18/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.0685\n",
            "Epoch 19/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.1715\n",
            "Epoch 20/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.1726\n",
            "Epoch 21/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.4215\n",
            "Epoch 22/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.2477\n",
            "Epoch 23/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.0117\n",
            "Epoch 24/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.9115\n",
            "Epoch 25/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7613\n",
            "Epoch 26/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.1477\n",
            "Epoch 27/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.4509\n",
            "Epoch 28/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.9312\n",
            "Epoch 29/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7143\n",
            "Epoch 30/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.7236\n",
            "Epoch 31/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.8819\n",
            "Epoch 32/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7981\n",
            "Epoch 33/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7804\n",
            "Epoch 34/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.7587\n",
            "Epoch 35/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.7578\n",
            "Epoch 36/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.9084\n",
            "Epoch 37/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.7943\n",
            "Epoch 38/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 3.0093\n",
            "Epoch 39/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.8427\n",
            "Epoch 40/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7538\n",
            "Epoch 41/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.8690\n",
            "Epoch 42/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6002\n",
            "Epoch 43/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7271\n",
            "Epoch 44/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7771\n",
            "Epoch 45/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7307\n",
            "Epoch 46/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.8397\n",
            "Epoch 47/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6996\n",
            "Epoch 48/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7793\n",
            "Epoch 49/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7691\n",
            "Epoch 50/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7096\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4827\n",
            "[CV] END activation=relu, batch_size=32, epochs=50, neurons=64, optimizer=adam; total time=  42.8s\n",
            "Epoch 1/50\n",
            "208/208 [==============================] - 2s 3ms/step - loss: 230.0998\n",
            "Epoch 2/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5809\n",
            "Epoch 3/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5382\n",
            "Epoch 4/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5318\n",
            "Epoch 5/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5826\n",
            "Epoch 6/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5990\n",
            "Epoch 7/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6048\n",
            "Epoch 8/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5614\n",
            "Epoch 9/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.5906\n",
            "Epoch 10/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5574\n",
            "Epoch 11/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5894\n",
            "Epoch 12/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6533\n",
            "Epoch 13/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6427\n",
            "Epoch 14/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6046\n",
            "Epoch 15/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6943\n",
            "Epoch 16/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7717\n",
            "Epoch 17/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6745\n",
            "Epoch 18/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7366\n",
            "Epoch 19/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.9080\n",
            "Epoch 20/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7883\n",
            "Epoch 21/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7414\n",
            "Epoch 22/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7509\n",
            "Epoch 23/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.7298\n",
            "Epoch 24/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.8249\n",
            "Epoch 25/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.8019\n",
            "Epoch 26/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9971\n",
            "Epoch 27/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.3239\n",
            "Epoch 28/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9415\n",
            "Epoch 29/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.7441\n",
            "Epoch 30/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7396\n",
            "Epoch 31/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.0470\n",
            "Epoch 32/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.9145\n",
            "Epoch 33/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.8231\n",
            "Epoch 34/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.9521\n",
            "Epoch 35/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.9999\n",
            "Epoch 36/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.9299\n",
            "Epoch 37/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.1786\n",
            "Epoch 38/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.9041\n",
            "Epoch 39/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7192\n",
            "Epoch 40/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.8530\n",
            "Epoch 41/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.9247\n",
            "Epoch 42/50\n",
            "208/208 [==============================] - 1s 4ms/step - loss: 1.7669\n",
            "Epoch 43/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7876\n",
            "Epoch 44/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7676\n",
            "Epoch 45/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.0786\n",
            "Epoch 46/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.9206\n",
            "Epoch 47/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.8433\n",
            "Epoch 48/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.9147\n",
            "Epoch 49/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.8710\n",
            "Epoch 50/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9729\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.6278\n",
            "[CV] END activation=relu, batch_size=32, epochs=50, neurons=64, optimizer=adam; total time=  27.1s\n",
            "Epoch 1/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 35.7538\n",
            "Epoch 2/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 16.5062\n",
            "Epoch 3/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 10.8406\n",
            "Epoch 4/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 8.3873\n",
            "Epoch 5/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 6.3542\n",
            "Epoch 6/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 5.2806\n",
            "Epoch 7/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 4.6725\n",
            "Epoch 8/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 4.1324\n",
            "Epoch 9/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.7315\n",
            "Epoch 10/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.3373\n",
            "Epoch 11/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.1674\n",
            "Epoch 12/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.1224\n",
            "Epoch 13/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.0157\n",
            "Epoch 14/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.8897\n",
            "Epoch 15/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.8445\n",
            "Epoch 16/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.8137\n",
            "Epoch 17/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7240\n",
            "Epoch 18/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7345\n",
            "Epoch 19/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.7086\n",
            "Epoch 20/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6382\n",
            "Epoch 21/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6248\n",
            "Epoch 22/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6094\n",
            "Epoch 23/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.5834\n",
            "Epoch 24/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.5848\n",
            "Epoch 25/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.5536\n",
            "Epoch 26/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.5514\n",
            "Epoch 27/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.5330\n",
            "Epoch 28/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.5233\n",
            "Epoch 29/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.5251\n",
            "Epoch 30/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.5213\n",
            "Epoch 31/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.5166\n",
            "Epoch 32/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.5154\n",
            "Epoch 33/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.5007\n",
            "Epoch 34/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4963\n",
            "Epoch 35/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4908\n",
            "Epoch 36/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4889\n",
            "Epoch 37/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4787\n",
            "Epoch 38/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4885\n",
            "Epoch 39/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4849\n",
            "Epoch 40/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4798\n",
            "Epoch 41/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4860\n",
            "Epoch 42/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4911\n",
            "Epoch 43/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4735\n",
            "Epoch 44/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4800\n",
            "Epoch 45/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4749\n",
            "Epoch 46/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4849\n",
            "Epoch 47/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4717\n",
            "Epoch 48/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4805\n",
            "Epoch 49/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4661\n",
            "Epoch 50/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4661\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4752\n",
            "[CV] END activation=relu, batch_size=32, epochs=50, neurons=64, optimizer=rmsprop; total time=  25.6s\n",
            "Epoch 1/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 42.3163\n",
            "Epoch 2/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 17.6241\n",
            "Epoch 3/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 13.8447\n",
            "Epoch 4/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 11.0492\n",
            "Epoch 5/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 8.1057\n",
            "Epoch 6/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 5.7977\n",
            "Epoch 7/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 4.3114\n",
            "Epoch 8/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 3.0880\n",
            "Epoch 9/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.6001\n",
            "Epoch 10/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.2526\n",
            "Epoch 11/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.0023\n",
            "Epoch 12/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.9427\n",
            "Epoch 13/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.8005\n",
            "Epoch 14/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.7081\n",
            "Epoch 15/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6708\n",
            "Epoch 16/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6442\n",
            "Epoch 17/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6216\n",
            "Epoch 18/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5947\n",
            "Epoch 19/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.6050\n",
            "Epoch 20/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5650\n",
            "Epoch 21/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5602\n",
            "Epoch 22/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5217\n",
            "Epoch 23/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5382\n",
            "Epoch 24/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5291\n",
            "Epoch 25/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.5264\n",
            "Epoch 26/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.5107\n",
            "Epoch 27/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.5020\n",
            "Epoch 28/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.5030\n",
            "Epoch 29/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4986\n",
            "Epoch 30/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4993\n",
            "Epoch 31/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4984\n",
            "Epoch 32/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4893\n",
            "Epoch 33/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4988\n",
            "Epoch 34/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4825\n",
            "Epoch 35/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4872\n",
            "Epoch 36/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4798\n",
            "Epoch 37/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4774\n",
            "Epoch 38/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4775\n",
            "Epoch 39/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4781\n",
            "Epoch 40/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4755\n",
            "Epoch 41/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4721\n",
            "Epoch 42/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4691\n",
            "Epoch 43/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4678\n",
            "Epoch 44/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4645\n",
            "Epoch 45/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4718\n",
            "Epoch 46/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4707\n",
            "Epoch 47/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4707\n",
            "Epoch 48/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4669\n",
            "Epoch 49/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4638\n",
            "Epoch 50/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4731\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4551\n",
            "[CV] END activation=relu, batch_size=32, epochs=50, neurons=64, optimizer=rmsprop; total time=  25.1s\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 1s 2ms/step - loss: 20.4608\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.6838\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5683\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.5788\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.5484\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.5749\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.6040\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.6289\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5932\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5871\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5410\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.6695\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5688\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.6048\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.5661\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.6741\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.6555\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.6175\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.5791\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5849\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5488\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5688\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.6625\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.6921\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5978\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.7107\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.6759\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.6362\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5886\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.7651\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.7888\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.6652\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.6960\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.7499\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5806\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.7159\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.7186\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5616\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.6034\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.6838\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.7298\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5535\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.6615\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5462\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5307\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5402\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.7244\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.6136\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.6363\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.6553\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.0236\n",
            "[CV] END activation=relu, batch_size=64, epochs=50, neurons=16, optimizer=adam; total time=  13.9s\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 1s 2ms/step - loss: 40.3173\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.8635\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5606\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5215\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5330\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5042\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4964\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5123\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5033\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4997\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5045\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5095\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5153\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4994\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4857\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4952\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4962\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5864\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4966\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4935\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5219\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5257\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5019\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5012\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5092\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5310\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5580\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5062\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5864\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5598\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5496\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5083\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5829\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5260\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5171\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5094\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5754\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5130\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5555\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5374\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5255\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5486\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5259\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5915\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5423\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5583\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5547\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5269\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5555\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5419\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.7272\n",
            "[CV] END activation=relu, batch_size=64, epochs=50, neurons=16, optimizer=adam; total time=  14.1s\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 1s 2ms/step - loss: 12.6560\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 5.3920\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 4.7490\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 4.6754\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 4.5651\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 4.4750\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 4.5900\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 4.4177\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 4.5426\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 4.1865\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 4.4428\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 4.4144\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 4.1663\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 4.1542\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 4.3319\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 4.1251\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 4.2222\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 4.1272\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 4.0907\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 3.9633\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 4.0107\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 4.0138\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 3.8131\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 4.0093\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 3.7914\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.8026\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.9592\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.9646\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.6078\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.8070\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.8608\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.6851\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.6282\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.6722\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.7714\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.5874\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.6309\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.5606\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.5613\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.5251\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.6034\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.5770\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.5702\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.2814\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.4639\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.3795\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.3972\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.3902\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.3214\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.3588\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.8318\n",
            "[CV] END activation=relu, batch_size=64, epochs=50, neurons=16, optimizer=rmsprop; total time=  21.5s\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 1s 2ms/step - loss: 7.4370\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.4342\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.3953\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.4228\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.2566\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.2550\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.2234\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.1566\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.1973\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.2625\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.1434\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.0943\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.1116\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.0987\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.0562\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.0713\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.0137\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.0400\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.0033\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.9489\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.0086\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.0028\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.9192\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.9644\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.9235\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.9240\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.9193\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.8421\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.9060\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.8739\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.8257\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.8586\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.8638\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.7607\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.7836\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.7708\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.7622\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.7641\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.7604\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.7173\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.7077\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.7382\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.6778\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.6627\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.6788\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.6666\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.6265\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.6303\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.6125\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.6113\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5478\n",
            "[CV] END activation=relu, batch_size=64, epochs=50, neurons=16, optimizer=rmsprop; total time=  13.7s\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 1s 2ms/step - loss: 158.4107\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5879\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5526\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5847\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5803\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5202\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.6955\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5406\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5968\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5592\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5381\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.6132\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5924\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.6449\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.6111\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.6638\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.6526\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5899\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.6727\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5526\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.7273\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5275\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.6159\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.6915\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5832\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5634\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.6235\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.7287\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5965\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.6230\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.9856\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.6590\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.6239\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.7612\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.6785\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.6512\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.7543\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.6028\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.7649\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 3.0188\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.7553\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.6492\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.5762\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.8292\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.8321\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.7124\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.6161\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 3.5274\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.6493\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.6718\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.6382\n",
            "[CV] END activation=relu, batch_size=64, epochs=50, neurons=32, optimizer=adam; total time=  14.8s\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 1s 2ms/step - loss: 1417.5117\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5862\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5634\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5560\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5483\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5433\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5341\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5310\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5264\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5209\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5135\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5186\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5135\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5205\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5038\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5031\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5088\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5082\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5218\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5112\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5006\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5117\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5005\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5000\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5302\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5061\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5104\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4974\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5117\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5038\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5091\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4914\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5213\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5098\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5111\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5109\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5109\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5215\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4983\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5038\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5025\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5329\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5071\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5214\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5053\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5786\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5685\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5118\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5220\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.6405\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5808\n",
            "[CV] END activation=relu, batch_size=64, epochs=50, neurons=32, optimizer=adam; total time=  14.5s\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 1s 3ms/step - loss: 45.7210\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 13.5200\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 12.8811\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 11.9222\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 12.0802\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 11.4360\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 11.8736\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 10.1699\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 10.6715\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 10.1634\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 9.4542\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 9.6748\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 9.4625\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 8.7734\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 9.0379\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 8.1515\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 6.9125\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 6.9585\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 6.5806\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 6.1086\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 6.3586\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 6.0461\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 6.1124\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 6.0012\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 5.6223\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 5.3121\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 5.0894\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 4.7447\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 5.3140\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 4.9115\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 4.8760\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 4.7319\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 4.6091\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 4.5930\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 4.5501\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 4.6236\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 4.5281\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 4.2991\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 4.1338\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 4.0548\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 4.2898\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 4.1270\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 4.1207\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 3.8751\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 3.8822\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 3.9001\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.9405\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.6959\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.7595\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.7413\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.0962\n",
            "[CV] END activation=relu, batch_size=64, epochs=50, neurons=32, optimizer=rmsprop; total time=  16.7s\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 1s 2ms/step - loss: 5.6740\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.9626\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.4540\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.2579\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.0374\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.9010\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.8079\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5391\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.2613\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.3473\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.2504\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.1799\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.0998\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.0892\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.0973\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.9478\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.0133\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.9264\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.9053\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.9098\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.8051\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.7972\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.8142\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.8261\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.7468\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.7508\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.7148\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.7249\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.7034\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.6598\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.6826\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.6575\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.6561\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.6370\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.6246\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.6493\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5900\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.6035\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5863\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.6043\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5691\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5753\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5727\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5616\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5501\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5565\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5491\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5363\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5356\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5365\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.5786\n",
            "[CV] END activation=relu, batch_size=64, epochs=50, neurons=32, optimizer=rmsprop; total time=  21.8s\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 1s 3ms/step - loss: 70.9228\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.5563\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.6270\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.6708\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.6444\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.5921\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.6347\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.6585\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.6035\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.5738\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.6443\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.6051\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.5852\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.6036\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.8268\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.8743\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.5694\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.8432\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.8162\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.8779\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.8514\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.8705\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.8256\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.7460\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.7827\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.9515\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 3.1335\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.7814\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.7973\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.9327\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 3.2653\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.8375\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.9930\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 3.5915\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.9495\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 3.0991\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.9204\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.7872\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.8825\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.6457\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.7356\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.7637\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.8476\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.6377\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 3.2133\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 3.3510\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.9110\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.8155\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 3.0385\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.7556\n",
            "104/104 [==============================] - 1s 3ms/step - loss: 1.9934\n",
            "[CV] END activation=relu, batch_size=64, epochs=50, neurons=64, optimizer=adam; total time=  17.3s\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 2s 3ms/step - loss: 303.7095\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5789\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5744\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5332\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5169\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5142\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5250\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5095\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5005\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5277\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5773\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4943\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4894\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4994\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5055\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5391\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5507\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5219\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5100\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5593\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5345\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5424\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5688\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5106\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5357\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5599\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5691\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5048\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5185\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5572\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.6339\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.5844\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.6310\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5500\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5654\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5964\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.6647\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.6792\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5845\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5841\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5928\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5909\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5423\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6593\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7892\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.6285\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.6627\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.8020\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.7746\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6529\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.8364\n",
            "[CV] END activation=relu, batch_size=64, epochs=50, neurons=64, optimizer=adam; total time=  17.1s\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 1s 2ms/step - loss: 47.5283\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 18.2419\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 15.1192\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 12.2124\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 10.1981\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 9.4863\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 8.7896\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 7.8053\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 6.8348\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 6.2644\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 5.4783\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 4.7768\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 4.5851\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 4.1284\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 3.7148\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 3.7811\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 3.4799\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.2496\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 3.3257\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.2370\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.1089\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.0558\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 3.0624\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.8866\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.8638\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.8827\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.8034\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.7767\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.7164\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.7378\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.6838\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.6858\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.6580\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.6402\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.6436\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.6455\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.6208\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.6160\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.5680\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.5711\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.5653\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.5730\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.5512\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.5102\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.5066\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.4990\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.5158\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4899\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4868\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.4880\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4633\n",
            "[CV] END activation=relu, batch_size=64, epochs=50, neurons=64, optimizer=rmsprop; total time=  16.4s\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 1s 3ms/step - loss: 38.5769\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 17.0035\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 12.7984\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 10.8131\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 8.8810\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 8.3138\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 7.0123\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 6.3645\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 5.4192\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 5.0207\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 4.6142\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 4.3387\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 4.0338\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 3.5151\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 3.2220\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.9825\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.7342\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.5774\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4065\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.3581\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.0978\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.1108\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.8369\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.7554\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.8093\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.7818\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6663\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6110\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5757\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5878\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5559\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5608\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5565\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5711\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5433\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5510\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5165\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5106\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5045\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4939\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4945\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5077\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4846\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4963\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4877\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4966\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4862\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4876\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4814\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4831\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.4801\n",
            "[CV] END activation=relu, batch_size=64, epochs=50, neurons=64, optimizer=rmsprop; total time=  16.9s\n",
            "Epoch 1/50\n",
            "208/208 [==============================] - 2s 3ms/step - loss: 2.4915\n",
            "Epoch 2/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4691\n",
            "Epoch 3/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4683\n",
            "Epoch 4/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4720\n",
            "Epoch 5/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4669\n",
            "Epoch 6/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4670\n",
            "Epoch 7/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4671\n",
            "Epoch 8/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4719\n",
            "Epoch 9/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4644\n",
            "Epoch 10/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4683\n",
            "Epoch 11/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4661\n",
            "Epoch 12/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4672\n",
            "Epoch 13/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4623\n",
            "Epoch 14/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4633\n",
            "Epoch 15/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4673\n",
            "Epoch 16/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4621\n",
            "Epoch 17/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4608\n",
            "Epoch 18/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4655\n",
            "Epoch 19/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4613\n",
            "Epoch 20/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4578\n",
            "Epoch 21/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4613\n",
            "Epoch 22/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4596\n",
            "Epoch 23/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4587\n",
            "Epoch 24/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4638\n",
            "Epoch 25/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4649\n",
            "Epoch 26/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4645\n",
            "Epoch 27/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4625\n",
            "Epoch 28/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4625\n",
            "Epoch 29/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4641\n",
            "Epoch 30/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4648\n",
            "Epoch 31/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4591\n",
            "Epoch 32/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4593\n",
            "Epoch 33/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4606\n",
            "Epoch 34/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4637\n",
            "Epoch 35/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4625\n",
            "Epoch 36/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4580\n",
            "Epoch 37/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4601\n",
            "Epoch 38/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4565\n",
            "Epoch 39/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4609\n",
            "Epoch 40/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4607\n",
            "Epoch 41/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4596\n",
            "Epoch 42/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4583\n",
            "Epoch 43/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4596\n",
            "Epoch 44/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4576\n",
            "Epoch 45/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4619\n",
            "Epoch 46/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4597\n",
            "Epoch 47/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4576\n",
            "Epoch 48/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4584\n",
            "Epoch 49/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4686\n",
            "Epoch 50/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4637\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4667\n",
            "[CV] END activation=tanh, batch_size=32, epochs=50, neurons=16, optimizer=adam; total time=  28.7s\n",
            "Epoch 1/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.5222\n",
            "Epoch 2/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4774\n",
            "Epoch 3/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4752\n",
            "Epoch 4/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4728\n",
            "Epoch 5/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4748\n",
            "Epoch 6/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4724\n",
            "Epoch 7/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4747\n",
            "Epoch 8/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4727\n",
            "Epoch 9/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4730\n",
            "Epoch 10/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4693\n",
            "Epoch 11/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4735\n",
            "Epoch 12/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4675\n",
            "Epoch 13/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4695\n",
            "Epoch 14/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4691\n",
            "Epoch 15/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4697\n",
            "Epoch 16/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4705\n",
            "Epoch 17/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4708\n",
            "Epoch 18/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4643\n",
            "Epoch 19/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4681\n",
            "Epoch 20/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4687\n",
            "Epoch 21/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4679\n",
            "Epoch 22/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4662\n",
            "Epoch 23/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4673\n",
            "Epoch 24/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4660\n",
            "Epoch 25/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4711\n",
            "Epoch 26/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4681\n",
            "Epoch 27/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4667\n",
            "Epoch 28/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4664\n",
            "Epoch 29/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4675\n",
            "Epoch 30/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4653\n",
            "Epoch 31/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4640\n",
            "Epoch 32/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4655\n",
            "Epoch 33/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4674\n",
            "Epoch 34/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4627\n",
            "Epoch 35/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4686\n",
            "Epoch 36/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4690\n",
            "Epoch 37/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4673\n",
            "Epoch 38/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4676\n",
            "Epoch 39/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4652\n",
            "Epoch 40/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4663\n",
            "Epoch 41/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4641\n",
            "Epoch 42/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4681\n",
            "Epoch 43/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4685\n",
            "Epoch 44/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4646\n",
            "Epoch 45/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4647\n",
            "Epoch 46/50\n",
            "208/208 [==============================] - 1s 4ms/step - loss: 1.4648\n",
            "Epoch 47/50\n",
            "208/208 [==============================] - 1s 4ms/step - loss: 1.4644\n",
            "Epoch 48/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4637\n",
            "Epoch 49/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4656\n",
            "Epoch 50/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4647\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4655\n",
            "[CV] END activation=tanh, batch_size=32, epochs=50, neurons=16, optimizer=adam; total time=  28.5s\n",
            "Epoch 1/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4824\n",
            "Epoch 2/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4728\n",
            "Epoch 3/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4725\n",
            "Epoch 4/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4693\n",
            "Epoch 5/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4650\n",
            "Epoch 6/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4704\n",
            "Epoch 7/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4678\n",
            "Epoch 8/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4689\n",
            "Epoch 9/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4690\n",
            "Epoch 10/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4657\n",
            "Epoch 11/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4661\n",
            "Epoch 12/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4688\n",
            "Epoch 13/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4665\n",
            "Epoch 14/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4673\n",
            "Epoch 15/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4664\n",
            "Epoch 16/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4634\n",
            "Epoch 17/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4645\n",
            "Epoch 18/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4651\n",
            "Epoch 19/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4664\n",
            "Epoch 20/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4661\n",
            "Epoch 21/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4655\n",
            "Epoch 22/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4664\n",
            "Epoch 23/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4637\n",
            "Epoch 24/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4647\n",
            "Epoch 25/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4598\n",
            "Epoch 26/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4630\n",
            "Epoch 27/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4624\n",
            "Epoch 28/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4626\n",
            "Epoch 29/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4620\n",
            "Epoch 30/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4632\n",
            "Epoch 31/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4577\n",
            "Epoch 32/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4637\n",
            "Epoch 33/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4645\n",
            "Epoch 34/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4619\n",
            "Epoch 35/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4600\n",
            "Epoch 36/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4602\n",
            "Epoch 37/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4624\n",
            "Epoch 38/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4579\n",
            "Epoch 39/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4617\n",
            "Epoch 40/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4591\n",
            "Epoch 41/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4588\n",
            "Epoch 42/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4571\n",
            "Epoch 43/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4651\n",
            "Epoch 44/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4655\n",
            "Epoch 45/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4638\n",
            "Epoch 46/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4641\n",
            "Epoch 47/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4628\n",
            "Epoch 48/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4629\n",
            "Epoch 49/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4650\n",
            "Epoch 50/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4623\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4679\n",
            "[CV] END activation=tanh, batch_size=32, epochs=50, neurons=16, optimizer=rmsprop; total time=  42.4s\n",
            "Epoch 1/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4793\n",
            "Epoch 2/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4719\n",
            "Epoch 3/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4759\n",
            "Epoch 4/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4749\n",
            "Epoch 5/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4737\n",
            "Epoch 6/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4721\n",
            "Epoch 7/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4712\n",
            "Epoch 8/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4725\n",
            "Epoch 9/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4724\n",
            "Epoch 10/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4743\n",
            "Epoch 11/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4710\n",
            "Epoch 12/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4703\n",
            "Epoch 13/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4720\n",
            "Epoch 14/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4720\n",
            "Epoch 15/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4687\n",
            "Epoch 16/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4690\n",
            "Epoch 17/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4744\n",
            "Epoch 18/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4711\n",
            "Epoch 19/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4702\n",
            "Epoch 20/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4689\n",
            "Epoch 21/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4690\n",
            "Epoch 22/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4701\n",
            "Epoch 23/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4696\n",
            "Epoch 24/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4718\n",
            "Epoch 25/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4692\n",
            "Epoch 26/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4712\n",
            "Epoch 27/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4713\n",
            "Epoch 28/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4707\n",
            "Epoch 29/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4700\n",
            "Epoch 30/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4684\n",
            "Epoch 31/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4673\n",
            "Epoch 32/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4701\n",
            "Epoch 33/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4698\n",
            "Epoch 34/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4683\n",
            "Epoch 35/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4668\n",
            "Epoch 36/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4705\n",
            "Epoch 37/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4691\n",
            "Epoch 38/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4685\n",
            "Epoch 39/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4708\n",
            "Epoch 40/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4690\n",
            "Epoch 41/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4676\n",
            "Epoch 42/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4663\n",
            "Epoch 43/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4670\n",
            "Epoch 44/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4663\n",
            "Epoch 45/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4671\n",
            "Epoch 46/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4625\n",
            "Epoch 47/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4654\n",
            "Epoch 48/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4645\n",
            "Epoch 49/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4623\n",
            "Epoch 50/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4647\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4545\n",
            "[CV] END activation=tanh, batch_size=32, epochs=50, neurons=16, optimizer=rmsprop; total time=  42.1s\n",
            "Epoch 1/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.5373\n",
            "Epoch 2/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4720\n",
            "Epoch 3/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4816\n",
            "Epoch 4/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4684\n",
            "Epoch 5/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4706\n",
            "Epoch 6/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4696\n",
            "Epoch 7/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4679\n",
            "Epoch 8/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4683\n",
            "Epoch 9/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4636\n",
            "Epoch 10/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4595\n",
            "Epoch 11/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4642\n",
            "Epoch 12/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4605\n",
            "Epoch 13/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4636\n",
            "Epoch 14/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4649\n",
            "Epoch 15/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4656\n",
            "Epoch 16/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4656\n",
            "Epoch 17/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4586\n",
            "Epoch 18/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4652\n",
            "Epoch 19/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4585\n",
            "Epoch 20/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4598\n",
            "Epoch 21/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4591\n",
            "Epoch 22/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4591\n",
            "Epoch 23/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4609\n",
            "Epoch 24/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4610\n",
            "Epoch 25/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4580\n",
            "Epoch 26/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4584\n",
            "Epoch 27/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4615\n",
            "Epoch 28/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4575\n",
            "Epoch 29/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4556\n",
            "Epoch 30/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4580\n",
            "Epoch 31/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4609\n",
            "Epoch 32/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4597\n",
            "Epoch 33/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4565\n",
            "Epoch 34/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4615\n",
            "Epoch 35/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4589\n",
            "Epoch 36/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4554\n",
            "Epoch 37/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4614\n",
            "Epoch 38/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4563\n",
            "Epoch 39/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4622\n",
            "Epoch 40/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4589\n",
            "Epoch 41/50\n",
            "208/208 [==============================] - 1s 4ms/step - loss: 2.4598\n",
            "Epoch 42/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4594\n",
            "Epoch 43/50\n",
            "208/208 [==============================] - 1s 4ms/step - loss: 2.4567\n",
            "Epoch 44/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4566\n",
            "Epoch 45/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4557\n",
            "Epoch 46/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4613\n",
            "Epoch 47/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4585\n",
            "Epoch 48/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4551\n",
            "Epoch 49/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4584\n",
            "Epoch 50/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4580\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4665\n",
            "[CV] END activation=tanh, batch_size=32, epochs=50, neurons=32, optimizer=adam; total time=  42.4s\n",
            "Epoch 1/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.5538\n",
            "Epoch 2/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4788\n",
            "Epoch 3/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4750\n",
            "Epoch 4/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4723\n",
            "Epoch 5/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4727\n",
            "Epoch 6/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4720\n",
            "Epoch 7/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4729\n",
            "Epoch 8/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4726\n",
            "Epoch 9/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4662\n",
            "Epoch 10/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4702\n",
            "Epoch 11/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4691\n",
            "Epoch 12/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4733\n",
            "Epoch 13/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4686\n",
            "Epoch 14/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4655\n",
            "Epoch 15/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4686\n",
            "Epoch 16/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4703\n",
            "Epoch 17/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4677\n",
            "Epoch 18/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4629\n",
            "Epoch 19/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4634\n",
            "Epoch 20/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4679\n",
            "Epoch 21/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4643\n",
            "Epoch 22/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4637\n",
            "Epoch 23/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4601\n",
            "Epoch 24/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4614\n",
            "Epoch 25/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4633\n",
            "Epoch 26/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4615\n",
            "Epoch 27/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4661\n",
            "Epoch 28/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4642\n",
            "Epoch 29/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4579\n",
            "Epoch 30/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4621\n",
            "Epoch 31/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4612\n",
            "Epoch 32/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4602\n",
            "Epoch 33/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4601\n",
            "Epoch 34/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4600\n",
            "Epoch 35/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4638\n",
            "Epoch 36/50\n",
            "208/208 [==============================] - 1s 4ms/step - loss: 1.4577\n",
            "Epoch 37/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4567\n",
            "Epoch 38/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4576\n",
            "Epoch 39/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4621\n",
            "Epoch 40/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4554\n",
            "Epoch 41/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4544\n",
            "Epoch 42/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4567\n",
            "Epoch 43/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4598\n",
            "Epoch 44/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4529\n",
            "Epoch 45/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4557\n",
            "Epoch 46/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4564\n",
            "Epoch 47/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4568\n",
            "Epoch 48/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4600\n",
            "Epoch 49/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4552\n",
            "Epoch 50/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4535\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4722\n",
            "[CV] END activation=tanh, batch_size=32, epochs=50, neurons=32, optimizer=adam; total time=  29.8s\n",
            "Epoch 1/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4879\n",
            "Epoch 2/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4805\n",
            "Epoch 3/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4750\n",
            "Epoch 4/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4760\n",
            "Epoch 5/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4720\n",
            "Epoch 6/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4683\n",
            "Epoch 7/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4734\n",
            "Epoch 8/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4744\n",
            "Epoch 9/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4718\n",
            "Epoch 10/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4716\n",
            "Epoch 11/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4728\n",
            "Epoch 12/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4694\n",
            "Epoch 13/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4695\n",
            "Epoch 14/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4687\n",
            "Epoch 15/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4688\n",
            "Epoch 16/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4701\n",
            "Epoch 17/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4669\n",
            "Epoch 18/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4628\n",
            "Epoch 19/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4631\n",
            "Epoch 20/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4665\n",
            "Epoch 21/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4659\n",
            "Epoch 22/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4681\n",
            "Epoch 23/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4624\n",
            "Epoch 24/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4629\n",
            "Epoch 25/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4674\n",
            "Epoch 26/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4630\n",
            "Epoch 27/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4649\n",
            "Epoch 28/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4620\n",
            "Epoch 29/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4630\n",
            "Epoch 30/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4608\n",
            "Epoch 31/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4602\n",
            "Epoch 32/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4611\n",
            "Epoch 33/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4607\n",
            "Epoch 34/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4645\n",
            "Epoch 35/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4655\n",
            "Epoch 36/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4657\n",
            "Epoch 37/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4618\n",
            "Epoch 38/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4588\n",
            "Epoch 39/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4614\n",
            "Epoch 40/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4629\n",
            "Epoch 41/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4613\n",
            "Epoch 42/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4575\n",
            "Epoch 43/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4627\n",
            "Epoch 44/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4655\n",
            "Epoch 45/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4603\n",
            "Epoch 46/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4601\n",
            "Epoch 47/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4621\n",
            "Epoch 48/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4601\n",
            "Epoch 49/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4602\n",
            "Epoch 50/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4637\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4757\n",
            "[CV] END activation=tanh, batch_size=32, epochs=50, neurons=32, optimizer=rmsprop; total time=  27.8s\n",
            "Epoch 1/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.7575\n",
            "Epoch 2/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4824\n",
            "Epoch 3/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4798\n",
            "Epoch 4/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4790\n",
            "Epoch 5/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4797\n",
            "Epoch 6/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4781\n",
            "Epoch 7/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4750\n",
            "Epoch 8/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4766\n",
            "Epoch 9/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4727\n",
            "Epoch 10/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4734\n",
            "Epoch 11/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4732\n",
            "Epoch 12/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4680\n",
            "Epoch 13/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4658\n",
            "Epoch 14/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4660\n",
            "Epoch 15/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4667\n",
            "Epoch 16/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4663\n",
            "Epoch 17/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4713\n",
            "Epoch 18/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4676\n",
            "Epoch 19/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4664\n",
            "Epoch 20/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4657\n",
            "Epoch 21/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4644\n",
            "Epoch 22/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4656\n",
            "Epoch 23/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4664\n",
            "Epoch 24/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4627\n",
            "Epoch 25/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4612\n",
            "Epoch 26/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4633\n",
            "Epoch 27/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4661\n",
            "Epoch 28/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4676\n",
            "Epoch 29/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4615\n",
            "Epoch 30/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4672\n",
            "Epoch 31/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4594\n",
            "Epoch 32/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4674\n",
            "Epoch 33/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4610\n",
            "Epoch 34/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4594\n",
            "Epoch 35/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4621\n",
            "Epoch 36/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4634\n",
            "Epoch 37/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4635\n",
            "Epoch 38/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4663\n",
            "Epoch 39/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4640\n",
            "Epoch 40/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4640\n",
            "Epoch 41/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4621\n",
            "Epoch 42/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4608\n",
            "Epoch 43/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4639\n",
            "Epoch 44/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4641\n",
            "Epoch 45/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4594\n",
            "Epoch 46/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4619\n",
            "Epoch 47/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4554\n",
            "Epoch 48/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4582\n",
            "Epoch 49/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4553\n",
            "Epoch 50/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4552\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4482\n",
            "[CV] END activation=tanh, batch_size=32, epochs=50, neurons=32, optimizer=rmsprop; total time=  42.4s\n",
            "Epoch 1/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.5165\n",
            "Epoch 2/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4953\n",
            "Epoch 3/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4843\n",
            "Epoch 4/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4825\n",
            "Epoch 5/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4735\n",
            "Epoch 6/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4697\n",
            "Epoch 7/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4708\n",
            "Epoch 8/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4690\n",
            "Epoch 9/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4694\n",
            "Epoch 10/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4764\n",
            "Epoch 11/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4726\n",
            "Epoch 12/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4693\n",
            "Epoch 13/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4681\n",
            "Epoch 14/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4705\n",
            "Epoch 15/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4647\n",
            "Epoch 16/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4650\n",
            "Epoch 17/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4733\n",
            "Epoch 18/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4645\n",
            "Epoch 19/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4666\n",
            "Epoch 20/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4716\n",
            "Epoch 21/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4679\n",
            "Epoch 22/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4688\n",
            "Epoch 23/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4693\n",
            "Epoch 24/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4729\n",
            "Epoch 25/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4645\n",
            "Epoch 26/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4659\n",
            "Epoch 27/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4653\n",
            "Epoch 28/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4647\n",
            "Epoch 29/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4633\n",
            "Epoch 30/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4643\n",
            "Epoch 31/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4604\n",
            "Epoch 32/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4644\n",
            "Epoch 33/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4605\n",
            "Epoch 34/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4658\n",
            "Epoch 35/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4663\n",
            "Epoch 36/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4639\n",
            "Epoch 37/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4697\n",
            "Epoch 38/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4628\n",
            "Epoch 39/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4647\n",
            "Epoch 40/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4629\n",
            "Epoch 41/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4615\n",
            "Epoch 42/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4629\n",
            "Epoch 43/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4655\n",
            "Epoch 44/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4626\n",
            "Epoch 45/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4565\n",
            "Epoch 46/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4612\n",
            "Epoch 47/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4606\n",
            "Epoch 48/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4576\n",
            "Epoch 49/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4628\n",
            "Epoch 50/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4598\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4665\n",
            "[CV] END activation=tanh, batch_size=32, epochs=50, neurons=64, optimizer=adam; total time=  42.4s\n",
            "Epoch 1/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.5120\n",
            "Epoch 2/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4785\n",
            "Epoch 3/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4801\n",
            "Epoch 4/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4758\n",
            "Epoch 5/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4727\n",
            "Epoch 6/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4735\n",
            "Epoch 7/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4728\n",
            "Epoch 8/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4743\n",
            "Epoch 9/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4682\n",
            "Epoch 10/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4748\n",
            "Epoch 11/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4708\n",
            "Epoch 12/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4802\n",
            "Epoch 13/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4673\n",
            "Epoch 14/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4721\n",
            "Epoch 15/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4701\n",
            "Epoch 16/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4633\n",
            "Epoch 17/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4659\n",
            "Epoch 18/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4701\n",
            "Epoch 19/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4710\n",
            "Epoch 20/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4675\n",
            "Epoch 21/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4666\n",
            "Epoch 22/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4649\n",
            "Epoch 23/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4706\n",
            "Epoch 24/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4645\n",
            "Epoch 25/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4635\n",
            "Epoch 26/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4647\n",
            "Epoch 27/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4658\n",
            "Epoch 28/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4692\n",
            "Epoch 29/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4680\n",
            "Epoch 30/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4673\n",
            "Epoch 31/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4670\n",
            "Epoch 32/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4600\n",
            "Epoch 33/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4667\n",
            "Epoch 34/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4555\n",
            "Epoch 35/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4631\n",
            "Epoch 36/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4626\n",
            "Epoch 37/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4570\n",
            "Epoch 38/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4628\n",
            "Epoch 39/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4621\n",
            "Epoch 40/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4611\n",
            "Epoch 41/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4586\n",
            "Epoch 42/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4567\n",
            "Epoch 43/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4563\n",
            "Epoch 44/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4553\n",
            "Epoch 45/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4533\n",
            "Epoch 46/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4511\n",
            "Epoch 47/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4525\n",
            "Epoch 48/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4564\n",
            "Epoch 49/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4512\n",
            "Epoch 50/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4520\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4600\n",
            "[CV] END activation=tanh, batch_size=32, epochs=50, neurons=64, optimizer=adam; total time=  29.9s\n",
            "Epoch 1/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.5378\n",
            "Epoch 2/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.5096\n",
            "Epoch 3/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4974\n",
            "Epoch 4/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4866\n",
            "Epoch 5/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4822\n",
            "Epoch 6/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4807\n",
            "Epoch 7/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4768\n",
            "Epoch 8/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4728\n",
            "Epoch 9/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4766\n",
            "Epoch 10/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4757\n",
            "Epoch 11/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4720\n",
            "Epoch 12/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4689\n",
            "Epoch 13/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4696\n",
            "Epoch 14/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4698\n",
            "Epoch 15/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4698\n",
            "Epoch 16/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4659\n",
            "Epoch 17/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4641\n",
            "Epoch 18/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4710\n",
            "Epoch 19/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4654\n",
            "Epoch 20/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4692\n",
            "Epoch 21/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4651\n",
            "Epoch 22/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4687\n",
            "Epoch 23/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4626\n",
            "Epoch 24/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4750\n",
            "Epoch 25/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4710\n",
            "Epoch 26/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4659\n",
            "Epoch 27/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4676\n",
            "Epoch 28/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4679\n",
            "Epoch 29/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4675\n",
            "Epoch 30/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4694\n",
            "Epoch 31/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4662\n",
            "Epoch 32/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 2.4678\n",
            "Epoch 33/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4708\n",
            "Epoch 34/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 2.4693\n",
            "Epoch 35/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4649\n",
            "Epoch 36/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4694\n",
            "Epoch 37/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4645\n",
            "Epoch 38/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4618\n",
            "Epoch 39/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4682\n",
            "Epoch 40/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4682\n",
            "Epoch 41/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4679\n",
            "Epoch 42/50\n",
            "208/208 [==============================] - 1s 4ms/step - loss: 2.4685\n",
            "Epoch 43/50\n",
            "208/208 [==============================] - 1s 4ms/step - loss: 2.4692\n",
            "Epoch 44/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4679\n",
            "Epoch 45/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4661\n",
            "Epoch 46/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4676\n",
            "Epoch 47/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4659\n",
            "Epoch 48/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4643\n",
            "Epoch 49/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4700\n",
            "Epoch 50/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.4689\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.5251\n",
            "[CV] END activation=tanh, batch_size=32, epochs=50, neurons=64, optimizer=rmsprop; total time=  42.4s\n",
            "Epoch 1/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.5315\n",
            "Epoch 2/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.5091\n",
            "Epoch 3/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4962\n",
            "Epoch 4/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4844\n",
            "Epoch 5/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4842\n",
            "Epoch 6/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4828\n",
            "Epoch 7/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4771\n",
            "Epoch 8/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4725\n",
            "Epoch 9/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4765\n",
            "Epoch 10/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4724\n",
            "Epoch 11/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4725\n",
            "Epoch 12/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4681\n",
            "Epoch 13/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4703\n",
            "Epoch 14/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4727\n",
            "Epoch 15/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4733\n",
            "Epoch 16/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4699\n",
            "Epoch 17/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4681\n",
            "Epoch 18/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4689\n",
            "Epoch 19/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4656\n",
            "Epoch 20/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4702\n",
            "Epoch 21/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4642\n",
            "Epoch 22/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4650\n",
            "Epoch 23/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4678\n",
            "Epoch 24/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4686\n",
            "Epoch 25/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4653\n",
            "Epoch 26/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4646\n",
            "Epoch 27/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4629\n",
            "Epoch 28/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4648\n",
            "Epoch 29/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4692\n",
            "Epoch 30/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4701\n",
            "Epoch 31/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4661\n",
            "Epoch 32/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4625\n",
            "Epoch 33/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4577\n",
            "Epoch 34/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4643\n",
            "Epoch 35/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4628\n",
            "Epoch 36/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.4620\n",
            "Epoch 37/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4638\n",
            "Epoch 38/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4638\n",
            "Epoch 39/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4592\n",
            "Epoch 40/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4618\n",
            "Epoch 41/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4613\n",
            "Epoch 42/50\n",
            "208/208 [==============================] - 0s 2ms/step - loss: 1.4605\n",
            "Epoch 43/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4561\n",
            "Epoch 44/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4607\n",
            "Epoch 45/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4616\n",
            "Epoch 46/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4568\n",
            "Epoch 47/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4555\n",
            "Epoch 48/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4573\n",
            "Epoch 49/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4527\n",
            "Epoch 50/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.4555\n",
            "208/208 [==============================] - 2s 2ms/step - loss: 2.4880\n",
            "[CV] END activation=tanh, batch_size=32, epochs=50, neurons=64, optimizer=rmsprop; total time=  43.9s\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 1s 3ms/step - loss: 2.5691\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4750\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4691\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4701\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4648\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4698\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4653\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4600\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4630\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.4614\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.4589\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4624\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4666\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4663\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4621\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4615\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4592\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4603\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4582\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4607\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.4575\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4614\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4597\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4592\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4644\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4623\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4594\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4638\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4626\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4619\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4622\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4589\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4641\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4599\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4608\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4556\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4631\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4610\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4629\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4600\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4613\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.4555\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4572\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4583\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4601\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4594\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4576\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4566\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.4580\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4594\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4637\n",
            "[CV] END activation=tanh, batch_size=64, epochs=50, neurons=16, optimizer=adam; total time=  17.6s\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 1s 3ms/step - loss: 1.6054\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4703\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4697\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4690\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4691\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4678\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4645\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4672\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4683\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4653\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4656\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4627\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4650\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4650\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4630\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4631\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.4633\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4633\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4611\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4671\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4631\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4615\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4654\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4615\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4619\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4627\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4601\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4612\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4603\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4591\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4597\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4606\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4599\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4592\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4601\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4606\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4575\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4612\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4595\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4574\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4589\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4612\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4595\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4586\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4589\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4581\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4564\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4554\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4581\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4589\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4665\n",
            "[CV] END activation=tanh, batch_size=64, epochs=50, neurons=16, optimizer=adam; total time=  22.2s\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 1s 2ms/step - loss: 2.7669\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4753\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4749\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4716\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4662\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4677\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4684\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4694\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4661\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.4615\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4657\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4666\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.4638\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4618\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4620\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4653\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4630\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4618\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4613\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4585\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4590\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4582\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.4613\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4597\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.4593\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.4612\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4582\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4644\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.4609\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4557\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.4639\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4623\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4617\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4572\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4615\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4612\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4606\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4568\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4578\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4605\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4582\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4612\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4589\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4577\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.4608\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4626\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4574\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.4591\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4558\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4579\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4668\n",
            "[CV] END activation=tanh, batch_size=64, epochs=50, neurons=16, optimizer=rmsprop; total time=  17.0s\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 1s 3ms/step - loss: 1.4787\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4753\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4722\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4730\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4709\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4701\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4689\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4704\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4703\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4706\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4674\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4677\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4674\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4676\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4679\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4680\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4683\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4678\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4693\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4686\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4679\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4687\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4672\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4668\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4672\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4669\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4661\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4681\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4668\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4668\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4687\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4680\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4668\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4691\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4690\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4681\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4678\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4640\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4703\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4692\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4659\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4660\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4650\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4647\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4659\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4652\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4653\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4640\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4664\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4644\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.4652\n",
            "[CV] END activation=tanh, batch_size=64, epochs=50, neurons=16, optimizer=rmsprop; total time=  22.2s\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 1s 3ms/step - loss: 2.5221\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4736\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4697\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4718\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4671\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4703\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4621\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4662\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4656\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4619\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4561\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4636\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4574\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4528\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4601\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4602\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4537\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4548\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4602\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4593\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4548\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4539\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4597\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4546\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4633\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4520\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4562\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4521\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.4542\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.4562\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4572\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4599\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.4611\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4613\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4587\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4595\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.4590\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4617\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4524\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.4632\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4568\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4583\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4644\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4608\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4571\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4599\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4585\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4566\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4573\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4542\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4670\n",
            "[CV] END activation=tanh, batch_size=64, epochs=50, neurons=32, optimizer=adam; total time=  17.6s\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 2s 3ms/step - loss: 1.5050\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4773\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4822\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4778\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4733\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4719\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4701\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4711\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4695\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4655\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4692\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4662\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4654\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4658\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4649\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4637\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4650\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4651\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4634\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4666\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4676\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4658\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4637\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4629\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4625\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4621\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4636\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4649\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4625\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4609\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4634\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4611\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4581\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4633\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4594\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4594\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4618\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4627\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4633\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4578\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4616\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4586\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4600\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4578\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4599\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4610\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4569\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4548\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4549\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4553\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.4648\n",
            "[CV] END activation=tanh, batch_size=64, epochs=50, neurons=32, optimizer=adam; total time=  22.5s\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 1s 4ms/step - loss: 2.5060\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4757\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4766\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4689\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4737\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4704\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4673\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4666\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.4692\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.4679\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4675\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4698\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4660\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.4662\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.4649\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4642\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4606\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4617\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4594\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4640\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4620\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.4621\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4577\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4584\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4617\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4633\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4609\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.4633\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4635\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4616\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4625\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4625\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4616\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4572\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4588\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.4589\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4596\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4580\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.4589\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.4584\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4586\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4607\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.4564\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4594\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4571\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.4578\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4580\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4548\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.4607\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4546\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4605\n",
            "[CV] END activation=tanh, batch_size=64, epochs=50, neurons=32, optimizer=rmsprop; total time=  22.2s\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 1s 3ms/step - loss: 1.5070\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4812\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4776\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4776\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4745\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4724\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4736\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4706\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4699\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4688\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4685\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4694\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4704\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4722\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4694\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4707\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4744\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4693\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4667\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4666\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4655\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4613\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4675\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4653\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4675\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4642\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4652\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4689\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4682\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4628\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4620\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4642\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4611\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4629\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4607\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4618\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4622\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4595\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4578\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4608\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4612\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4630\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4596\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4565\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4588\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4574\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4611\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4592\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4590\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4569\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.4574\n",
            "[CV] END activation=tanh, batch_size=64, epochs=50, neurons=32, optimizer=rmsprop; total time=  15.4s\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 2s 3ms/step - loss: 2.4984\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4876\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.5117\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4892\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4683\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4822\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4670\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4784\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4685\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4692\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4645\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4650\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4678\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.4667\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.4651\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.4586\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4635\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4692\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4623\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4628\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4643\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.4603\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.4592\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.4667\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4675\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4604\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4632\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4605\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.4605\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4573\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4647\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4590\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4595\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4584\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4630\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4584\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4615\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4648\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4580\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4574\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4616\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4626\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4593\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4605\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4572\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4595\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4530\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4615\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4565\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4551\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4780\n",
            "[CV] END activation=tanh, batch_size=64, epochs=50, neurons=64, optimizer=adam; total time=  22.4s\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 1s 3ms/step - loss: 1.4973\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4892\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4833\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4887\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4821\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4734\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4697\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4677\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4694\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4669\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4735\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4653\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4621\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4649\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4610\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4706\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4617\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4679\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4695\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4665\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4620\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4655\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4610\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4574\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4655\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4610\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4644\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4690\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4570\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4630\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4621\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4588\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4558\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4640\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4612\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4529\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4581\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4569\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4558\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4553\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4553\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4532\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4576\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4527\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4538\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4556\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4572\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4534\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4545\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4553\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.4607\n",
            "[CV] END activation=tanh, batch_size=64, epochs=50, neurons=64, optimizer=adam; total time=  21.8s\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 1s 3ms/step - loss: 2.5715\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.5020\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4922\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.4919\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4779\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4869\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4812\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4767\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4737\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4731\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.4720\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.4647\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.4709\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4606\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4703\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4624\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4644\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.4611\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.4628\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.4659\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.4628\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4642\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4631\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4550\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.4649\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4681\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4637\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4616\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4635\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4689\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4633\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4717\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4661\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4669\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4609\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4599\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4615\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4601\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4605\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4630\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4631\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4540\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4612\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4559\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4516\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4637\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 2.4564\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4634\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4597\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4589\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4518\n",
            "[CV] END activation=tanh, batch_size=64, epochs=50, neurons=64, optimizer=rmsprop; total time=  16.4s\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 1s 3ms/step - loss: 1.5448\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.5119\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5068\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4936\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4860\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4842\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4795\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4771\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4770\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4760\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4706\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4720\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4694\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4687\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4736\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4716\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4715\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4750\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4697\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4701\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4695\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4707\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4681\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4676\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4689\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4699\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4665\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4713\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4672\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4668\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4633\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4673\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4636\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4664\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4668\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4643\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4635\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4620\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4642\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4590\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4626\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4605\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4586\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4545\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4643\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4602\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4579\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4565\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4550\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.4564\n",
            "104/104 [==============================] - 1s 3ms/step - loss: 2.4523\n",
            "[CV] END activation=tanh, batch_size=64, epochs=50, neurons=64, optimizer=rmsprop; total time=  18.1s\n",
            "Epoch 1/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 2.0113\n",
            "Epoch 2/50\n",
            "208/208 [==============================] - 1s 4ms/step - loss: 1.9900\n",
            "Epoch 3/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9819\n",
            "Epoch 4/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9740\n",
            "Epoch 5/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9744\n",
            "Epoch 6/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9739\n",
            "Epoch 7/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9686\n",
            "Epoch 8/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9699\n",
            "Epoch 9/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9674\n",
            "Epoch 10/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9677\n",
            "Epoch 11/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9670\n",
            "Epoch 12/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9674\n",
            "Epoch 13/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9661\n",
            "Epoch 14/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9636\n",
            "Epoch 15/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9650\n",
            "Epoch 16/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9617\n",
            "Epoch 17/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9647\n",
            "Epoch 18/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9612\n",
            "Epoch 19/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9617\n",
            "Epoch 20/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9638\n",
            "Epoch 21/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9615\n",
            "Epoch 22/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9607\n",
            "Epoch 23/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9617\n",
            "Epoch 24/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9610\n",
            "Epoch 25/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9600\n",
            "Epoch 26/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9619\n",
            "Epoch 27/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9591\n",
            "Epoch 28/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9569\n",
            "Epoch 29/50\n",
            "208/208 [==============================] - 1s 2ms/step - loss: 1.9574\n",
            "Epoch 30/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9566\n",
            "Epoch 31/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9547\n",
            "Epoch 32/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9560\n",
            "Epoch 33/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9566\n",
            "Epoch 34/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9582\n",
            "Epoch 35/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9559\n",
            "Epoch 36/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9551\n",
            "Epoch 37/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9576\n",
            "Epoch 38/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9575\n",
            "Epoch 39/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9551\n",
            "Epoch 40/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9555\n",
            "Epoch 41/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9547\n",
            "Epoch 42/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9565\n",
            "Epoch 43/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9499\n",
            "Epoch 44/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9551\n",
            "Epoch 45/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9535\n",
            "Epoch 46/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9524\n",
            "Epoch 47/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9543\n",
            "Epoch 48/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9497\n",
            "Epoch 49/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9533\n",
            "Epoch 50/50\n",
            "208/208 [==============================] - 1s 3ms/step - loss: 1.9525\n",
            " : {'activation': 'tanh', 'batch_size': 64, 'epochs': 50, 'neurons': 64, 'optimizer': 'rmsprop'}\n",
            " : -1.9520184397697449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "history = model.fit(X_train, \n",
        "                    y_train,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    epochs=50,\n",
        "                    batch_size=64,\n",
        "                    use_multiprocessing=True,\n",
        "                    workers=4,\n",
        "                    verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5rCPo1fp47U",
        "outputId": "8fac1cee-8d82-4037-ccef-9205dc5b6335"
      },
      "execution_count": 457,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "208/208 - 1s - loss: 44.3795 - val_loss: 4.3763 - 1s/epoch - 6ms/step\n",
            "Epoch 2/50\n",
            "208/208 - 0s - loss: 2.0812 - val_loss: 4.3716 - 403ms/epoch - 2ms/step\n",
            "Epoch 3/50\n",
            "208/208 - 0s - loss: 2.0563 - val_loss: 4.2311 - 412ms/epoch - 2ms/step\n",
            "Epoch 4/50\n",
            "208/208 - 1s - loss: 2.0491 - val_loss: 4.1981 - 726ms/epoch - 3ms/step\n",
            "Epoch 5/50\n",
            "208/208 - 1s - loss: 2.0973 - val_loss: 4.3263 - 768ms/epoch - 4ms/step\n",
            "Epoch 6/50\n",
            "208/208 - 1s - loss: 2.0704 - val_loss: 4.1972 - 1s/epoch - 6ms/step\n",
            "Epoch 7/50\n",
            "208/208 - 1s - loss: 2.0581 - val_loss: 4.1864 - 1s/epoch - 5ms/step\n",
            "Epoch 8/50\n",
            "208/208 - 1s - loss: 2.0328 - val_loss: 4.3863 - 877ms/epoch - 4ms/step\n",
            "Epoch 9/50\n",
            "208/208 - 1s - loss: 2.0309 - val_loss: 4.3711 - 1s/epoch - 5ms/step\n",
            "Epoch 10/50\n",
            "208/208 - 1s - loss: 2.0777 - val_loss: 4.2035 - 904ms/epoch - 4ms/step\n",
            "Epoch 11/50\n",
            "208/208 - 1s - loss: 2.1428 - val_loss: 4.5902 - 646ms/epoch - 3ms/step\n",
            "Epoch 12/50\n",
            "208/208 - 0s - loss: 2.0918 - val_loss: 4.1913 - 427ms/epoch - 2ms/step\n",
            "Epoch 13/50\n",
            "208/208 - 1s - loss: 2.0891 - val_loss: 4.3399 - 663ms/epoch - 3ms/step\n",
            "Epoch 14/50\n",
            "208/208 - 1s - loss: 2.1551 - val_loss: 4.2584 - 626ms/epoch - 3ms/step\n",
            "Epoch 15/50\n",
            "208/208 - 1s - loss: 2.3040 - val_loss: 4.5105 - 697ms/epoch - 3ms/step\n",
            "Epoch 16/50\n",
            "208/208 - 1s - loss: 2.1730 - val_loss: 4.4841 - 641ms/epoch - 3ms/step\n",
            "Epoch 17/50\n",
            "208/208 - 1s - loss: 2.1302 - val_loss: 4.1884 - 515ms/epoch - 2ms/step\n",
            "Epoch 18/50\n",
            "208/208 - 0s - loss: 2.1040 - val_loss: 4.4214 - 500ms/epoch - 2ms/step\n",
            "Epoch 19/50\n",
            "208/208 - 0s - loss: 2.1695 - val_loss: 4.1782 - 421ms/epoch - 2ms/step\n",
            "Epoch 20/50\n",
            "208/208 - 0s - loss: 2.1179 - val_loss: 4.3766 - 429ms/epoch - 2ms/step\n",
            "Epoch 21/50\n",
            "208/208 - 1s - loss: 2.2190 - val_loss: 4.1808 - 504ms/epoch - 2ms/step\n",
            "Epoch 22/50\n",
            "208/208 - 0s - loss: 2.3565 - val_loss: 4.1841 - 419ms/epoch - 2ms/step\n",
            "Epoch 23/50\n",
            "208/208 - 0s - loss: 2.2389 - val_loss: 4.8353 - 419ms/epoch - 2ms/step\n",
            "Epoch 24/50\n",
            "208/208 - 0s - loss: 2.1606 - val_loss: 4.7144 - 421ms/epoch - 2ms/step\n",
            "Epoch 25/50\n",
            "208/208 - 0s - loss: 2.1485 - val_loss: 4.4361 - 429ms/epoch - 2ms/step\n",
            "Epoch 26/50\n",
            "208/208 - 0s - loss: 2.1323 - val_loss: 4.2123 - 418ms/epoch - 2ms/step\n",
            "Epoch 27/50\n",
            "208/208 - 0s - loss: 2.1077 - val_loss: 4.2108 - 446ms/epoch - 2ms/step\n",
            "Epoch 28/50\n",
            "208/208 - 1s - loss: 2.0900 - val_loss: 4.7063 - 501ms/epoch - 2ms/step\n",
            "Epoch 29/50\n",
            "208/208 - 0s - loss: 2.1366 - val_loss: 4.7723 - 415ms/epoch - 2ms/step\n",
            "Epoch 30/50\n",
            "208/208 - 1s - loss: 2.3109 - val_loss: 5.1347 - 505ms/epoch - 2ms/step\n",
            "Epoch 31/50\n",
            "208/208 - 0s - loss: 2.2697 - val_loss: 4.5670 - 499ms/epoch - 2ms/step\n",
            "Epoch 32/50\n",
            "208/208 - 0s - loss: 2.1909 - val_loss: 4.2008 - 416ms/epoch - 2ms/step\n",
            "Epoch 33/50\n",
            "208/208 - 0s - loss: 2.2028 - val_loss: 5.3355 - 482ms/epoch - 2ms/step\n",
            "Epoch 34/50\n",
            "208/208 - 0s - loss: 2.1664 - val_loss: 4.1876 - 496ms/epoch - 2ms/step\n",
            "Epoch 35/50\n",
            "208/208 - 0s - loss: 2.2832 - val_loss: 4.4534 - 498ms/epoch - 2ms/step\n",
            "Epoch 36/50\n",
            "208/208 - 1s - loss: 2.1521 - val_loss: 4.4423 - 516ms/epoch - 2ms/step\n",
            "Epoch 37/50\n",
            "208/208 - 0s - loss: 2.2067 - val_loss: 4.2666 - 434ms/epoch - 2ms/step\n",
            "Epoch 38/50\n",
            "208/208 - 1s - loss: 2.1537 - val_loss: 4.2317 - 506ms/epoch - 2ms/step\n",
            "Epoch 39/50\n",
            "208/208 - 1s - loss: 2.2874 - val_loss: 4.6518 - 597ms/epoch - 3ms/step\n",
            "Epoch 40/50\n",
            "208/208 - 1s - loss: 2.1177 - val_loss: 4.1786 - 636ms/epoch - 3ms/step\n",
            "Epoch 41/50\n",
            "208/208 - 1s - loss: 2.0533 - val_loss: 4.2706 - 655ms/epoch - 3ms/step\n",
            "Epoch 42/50\n",
            "208/208 - 1s - loss: 2.1043 - val_loss: 4.2463 - 629ms/epoch - 3ms/step\n",
            "Epoch 43/50\n",
            "208/208 - 0s - loss: 2.1175 - val_loss: 4.1822 - 427ms/epoch - 2ms/step\n",
            "Epoch 44/50\n",
            "208/208 - 0s - loss: 2.1822 - val_loss: 4.2943 - 417ms/epoch - 2ms/step\n",
            "Epoch 45/50\n",
            "208/208 - 0s - loss: 2.1652 - val_loss: 4.1823 - 417ms/epoch - 2ms/step\n",
            "Epoch 46/50\n",
            "208/208 - 0s - loss: 2.1132 - val_loss: 4.3129 - 430ms/epoch - 2ms/step\n",
            "Epoch 47/50\n",
            "208/208 - 0s - loss: 2.1006 - val_loss: 6.1346 - 415ms/epoch - 2ms/step\n",
            "Epoch 48/50\n",
            "208/208 - 1s - loss: 2.1896 - val_loss: 4.1932 - 512ms/epoch - 2ms/step\n",
            "Epoch 49/50\n",
            "208/208 - 0s - loss: 2.1520 - val_loss: 4.4577 - 422ms/epoch - 2ms/step\n",
            "Epoch 50/50\n",
            "208/208 - 0s - loss: 2.1791 - val_loss: 4.1905 - 435ms/epoch - 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test_scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDF11nOrqbD2",
        "outputId": "f97ee908-199a-4e46-d909-d73f85d6a574"
      },
      "execution_count": 458,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "104/104 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYsT1DNfqfkg",
        "outputId": "78ccd2cd-b31a-4d8a-ec50-fe042f26167f"
      },
      "execution_count": 459,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "104/104 [==============================] - 0s 2ms/step - loss: 4.3831\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.383090019226074"
            ]
          },
          "metadata": {},
          "execution_count": 459
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = pd.DataFrame({\n",
        "    'platform': [le_platform.fit_transform(['Wii'])],\n",
        "    'genre': [le_genre.fit_transform(['Sports'])[0]],\n",
        "    'publisher': [le_publisher.fit_transform(['Nintendo'])]\n",
        "})\n",
        "\n",
        "new_game_scaled = scaler.transform(input_data)\n",
        "print(new_game_scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUoKd9Ja7DwA",
        "outputId": "11e86a84-671e-45d3-c607-11a116cdc21b"
      },
      "execution_count": 460,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.8846309  -1.30993871 -1.65281005]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "price_pred = model.predict(new_game_scaled)\n",
        "\n",
        "# Print the predicted price\n",
        "print(price_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWpihHGB7WNS",
        "outputId": "ed4889b3-7b25-4dbc-ccf7-946f1e50e269"
      },
      "execution_count": 461,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 31ms/step\n",
            "[[1.3762939]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(history.history['loss'], label='   ')\n",
        "plt.plot(history.history['val_loss'], label='   ')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "It40Xd3UNhJF",
        "outputId": "5b89c01c-af4d-4704-e8ce-1d20cd85d4ae"
      },
      "execution_count": 462,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YGiVDo8Nnf4",
        "outputId": "978d0c92-5f8b-4474-8d8f-e8fc2e10cba2"
      },
      "execution_count": 463,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "104/104 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.plot([min(y_test), 5], [min(y_test), 5], '--k')\n",
        "plt.xlabel('True Values')\n",
        "plt.ylabel('Predisctions')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "nxohiiQ1Nou8",
        "outputId": "943a24e9-a342-4dd7-b22e-a345a0e7906a"
      },
      "execution_count": 471,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}